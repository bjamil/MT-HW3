There are three python programs here (-h for usage):

-evaluate: ranks a set of machine translation systems.

-check: confirms that the correct set of systems is ranked for the test set.

-grade: computes Spearman's rank correlation coefficient between a set
 of automatic rankings and human rankings of MT systems (dev set only).

The commands are designed to work in a pipeline. For instance, this is
a valid invocation:

> evaluate | grade 

As is this:

> evaluate -d data/test | check

The data directory contains two subdirectories, dev and test. Each
directory contains a set of foreign source sentences, human English 
reference translations, and a large number of machine translations from
different systems. The file answer_key.dev contains a human ranking of 
the machine translation systems in the dev directory. The dev and test
data were derived from recent WMT shared tasks.

